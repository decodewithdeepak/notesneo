# Neural Networks Syllabus

**Course code**: PCC-CSE-401G  
**Category**: Professional Core Course  
**Course title**: Neural Networks  

## Scheme and Credits

| | L | T | P | Credits |
|----------|---|---|---|---------|
| Semester 7 | 3 | 0 | 0 | 3 |

| | Marks |
|----------|-------|
| Class work | 25 |
| Exam | 75 |
| Total | 100 |
| Duration of Exam | 03 Hours |

## Objective of the course:
- To understand the different issues involved in the design and implementation of a Neural Networks.
- To study the basic of neural network and its activation functions.
- To understand and use of perceptron and its application in real world.
- To develop an understanding of essential NN concepts such as: learning, feed forward and feed backward.
- To design and build a simple NN model to solve a problem.

> **Note**: Examiner will set nine questions in total. Question one will be compulsory. Question one will have 6 parts of 2.5 marks each from all units and remaining eight questions of 15 marks each to be set by taking two questions from each unit. The students have to attempt five questions in total, first being compulsory and selecting one from each unit.

## UNIT 1
### Overview of Biological Neurons
Structure of biological neuron, neurobiological analogy, Biological neuron equivalencies to artificial neuron model, Evolution of neural network.

### Activation Functions
Threshold functions, Signum function, Sigmoid function, Tan hyperbolic function, Stochastic function, Ramp function, Linear function, Identity function.

### ANN Architecture
Feed forward network, Feed backward network, single and multilayer network, fully recurrent network.

## UNIT 2
### McCulloch and Pits Neural Network (MCP Model)
Architecture, Solution of AND, OR function using MCP model.

### Hebb Model
Architecture, training and testing, Hebb network for AND function.

### Perceptron Network
Architecture, training, Testing, single and multi-output model, Perceptron for AND function.

### Linear Function
Application of linear model, linear separability, solution of OR function using linear separability model.

## UNIT 3
### Learning
Supervised, Unsupervised, reinforcement learning, Gradient Descent algorithm, generalized delta learning rule, Hebbian learning, Competitive learning.

### Back Propagation Network
Architecture, training and testing.

## UNIT 4
### Associative Memory
Auto associative and Hetero associative memory and their architecture, training (insertion) and testing (Retrieval) algorithm using Hebb rule and Outer Product rule. Storage capacity, Testing of associative memory for missing and mistaken data, Bidirectional memory.

## Suggested Text Books
1. Introduction to artificial Neural systems by Jacek M. Zurada, 1994, Jaico Publ. House.
2. Principles of Soft Computing by S.N. Deepa, S.N. Sivanandam., Weley publication

## Suggested Reference Books
1. "Neural Networks: A Comprehensive formulation", Simon Haykin, 1998, AW
2. "Neural Networks", Kosko, 1992, PHI.
3. "Neural Network Fundamentals" â€“ N.K. Bose, P. Liang, 2002, T.M.H
4. Neural Network, T.N.Shankar, University Science Press
5. Neuro Fuzzy Systems, Lamba, V.K., University Science Press

## Course Outcomes
After completing the course the student will be able to:
- For a given conceptual problem student will able to analyze the problem and able to visualize in NN.
- Students will be familiar with different NN models.
- Students will be able to understand the concept of learning in NN.
